
# **INFORME DE INVESTIGACION**
![Enlace a GitHub](Assets/ups-icc.png)


### **Asignatura:** Estructura de Datos

### **Tema:** Proyecto de Complejidad y Eficiencia de Algoritmos


# Integrantes:
- Axel Banegas - [Enlace a GitHub](https://github.com/axelbanegas)
- Pedro Panjon - [Enlace a GitHub](https://github.com/PedroP57xd)

# Objetivos:

- Adquirir mayor conocimiento sobre la eficiencia de los distintos algoritmos.

- Poder reconocer la complejidad de los algoritmos implementados dentro de un programa.


# Marco Te√≥rico: 

## **1. Teor√≠a de la Complejidad**

*(Aqu√≠ el estudiante coloca su investigaci√≥n)*

### 1.1 Definici√≥n general
Es un enfoque cient√≠fico que estudia sistemas complejos (como los biol√≥gicos, sociales o naturales) reconociendo que no se pueden entender analizando sus partes de forma aislada, sino como un todo interconectado.

### 1.2 Importancia en la resoluci√≥n de problemas

La teor√≠a de la complejidad computacional es fundamental para entender qu√© tan dif√≠cil es resolver un problema con un algoritmo. No solo clasifica los problemas seg√∫n los recursos necesarios (tiempo y espacio), sino que tambi√©n gu√≠a la elecci√≥n y el dise√±o de soluciones eficientes.

  üîç  ¬øPor qu√© es importante?

- Permite evaluar la eficiencia de los algoritmos: Saber si un algoritmo es O(n), O(n¬≤) u O(2‚Åø) ayuda a anticipar su rendimiento a diferentes escalas.

-    Ayuda a identificar problemas intratables: Algunos problemas, como los NP-completos, no tienen soluciones eficientes conocidas. Reconocerlos permite evitar enfoques inviables y buscar aproximaciones o heur√≠sticas.

 -   Optimiza el uso de recursos: Un buen entendimiento de la complejidad evita desperdiciar tiempo computacional y memoria.

  -  Gu√≠a la toma de decisiones: En proyectos reales, un algoritmo ‚Äúperfecto‚Äù pero demasiado lento puede ser in√∫til. Analizar la complejidad ayuda a elegir la estrategia m√°s pr√°ctica.

   - Fomenta mejores pr√°cticas de desarrollo: Comprender el impacto del crecimiento de los datos obliga a escribir c√≥digo m√°s limpio, escalable y sostenible.

### 1.3 Eficiencia de algoritmos

* Coste temporal:

    El coste temporal de un algoritmo se refiere al n√∫mero de operaciones que debe realizar para completar su tarea en funci√≥n del tama√±o de la entrada n. Se mide con notaci√≥n Big-O, que describe c√≥mo crece el tiempo de ejecuci√≥n cuando aumentan los datos. Por ejemplo, una b√∫squeda lineal tiene un coste O(n) porque necesita recorrer todos los elementos, mientras que una b√∫squeda binaria reduce el tiempo a O(\log n) al dividir el problema en mitades sucesivas.

* Coste espacial:

    El coste espacial mide la cantidad de memoria que un algoritmo necesita para ejecutarse correctamente. Incluye la memoria fija (variables y c√≥digo), la memoria dependiente del tama√±o de la entrada y la memoria adicional usada en estructuras auxiliares o recursi√≥n. Por ejemplo, MergeSort requiere O(n) espacio extra para arreglos temporales, mientras que algoritmos in-place como Quicksort solo necesitan O(\log n) espacio por la pila de recursi√≥n.


### 1.4 Factores de tiempo de ejecuci√≥n

* Factores propios:

    Son caracter√≠sticas internas del algoritmo que determinan su eficiencia, independientemente del entorno donde se ejecute.

    Estructura del algoritmo: n√∫mero de bucles, recursi√≥n, llamadas anidadas, etc.

    Complejidad temporal y espacial: qu√© tan r√°pido crecen las operaciones respecto al tama√±o de entrada.

    Eficiencia de las operaciones usadas: b√∫squedas, ordenamientos, acceso a estructuras de datos, etc.

    Elecci√≥n de estructuras de datos: algunas permiten operaciones m√°s r√°pidas (por ejemplo, hash tables vs. listas).

    Estos factores no cambian seg√∫n el hardware: dependen solo del dise√±o del algoritmo.

* Factores circunstanciales:

    Son condiciones externas que pueden afectar el tiempo real que tarda un algoritmo en ejecutarse.

    - Hardware disponible: velocidad del procesador, n√∫mero de n√∫cleos, memoria RAM, disco, GPU.

    - Carga del sistema: otros procesos ejecut√°ndose simult√°neamente.

    - Lenguaje de programaci√≥n y compilador: algunos lenguajes generan c√≥digo m√°s optimizado.

    - Implementaci√≥n espec√≠fica de librer√≠as o funciones est√°ndar.

    - Sistema operativo y arquitectura.

    - Estos factores pueden variar incluso con el mismo algoritmo y afectan el rendimiento pr√°ctico.

üìä M√©todos de an√°lisis del rendimiento 
    
* An√°lisis te√≥rico:

    Estudia el rendimiento del algoritmo de forma abstracta, independientemente del hardware.

    - Utiliza notaciones como O(n), Œ©(n), Œò(n).

    - Permite comparar algoritmos seg√∫n su crecimiento asint√≥tico.

    - No mide tiempos reales, sino c√≥mo escalan las operaciones para entradas grandes.

    - Es √∫til para elegir el algoritmo m√°s adecuado desde una perspectiva general.

    Ejemplo: determinar que un algoritmo de ordenamiento es O(n log n) sin ejecutarlo.

* An√°lisis experimental

    Eval√∫a el comportamiento real del algoritmo mediante pruebas pr√°cticas.

    - Se mide el tiempo de ejecuci√≥n en distintos escenarios y tama√±os de entrada.

    - Permite observar el impacto de factores circunstanciales.

    - √ötil para comparar implementaciones, lenguajes, m√°quinas o versiones de c√≥digo.

    - Puede descubrir comportamientos inesperados no visibles en el an√°lisis te√≥rico.

    Ejemplo: medir cu√°nto tarda realmente un algoritmo para n = 10‚Å∂ en una m√°quina espec√≠fica.

### 1.5 Notaci√≥n de complejidad

* Big O:

    La notaci√≥n Big O describe el l√≠mite superior del crecimiento de un algoritmo, es decir, c√≥mo aumenta el n√∫mero de operaciones en funci√≥n del tama√±o de la entrada n. Se utiliza para expresar el peor comportamiento posible en t√©rminos de tiempo o espacio, ignorando constantes y factores menores. Por ejemplo, un algoritmo de ordenamiento r√°pido tiene complejidad O(n\log n) en promedio, lo que significa que su tiempo de ejecuci√≥n crece proporcionalmente a n\log n.

* Mejor caso:

     El mejor caso representa la situaci√≥n m√°s favorable para un algoritmo, cuando la entrada est√° en condiciones √≥ptimas y el n√∫mero de operaciones es m√≠nimo. Por ejemplo, en la b√∫squeda lineal, si el elemento buscado est√° en la primera posici√≥n, el coste es O(1). Aunque es √∫til conocerlo, rara vez se usa como referencia principal porque no refleja el comportamiento t√≠pico.
* Peor caso:

    El peor caso indica el m√°ximo n√∫mero de operaciones que un algoritmo puede necesitar, es decir, el escenario m√°s desfavorable. Es el m√°s utilizado en an√°lisis porque garantiza que el algoritmo no ser√° m√°s lento que ese l√≠mite. Por ejemplo, en la b√∫squeda lineal, si el elemento est√° al final o no existe, el coste es O(n).

* Caso promedio:

    El caso promedio estima el n√∫mero esperado de operaciones considerando todas las posibles entradas y su probabilidad de ocurrencia. Es m√°s realista que el mejor caso y m√°s optimista que el peor caso. Por ejemplo, en la b√∫squeda lineal, si el elemento est√° distribuido aleatoriamente, el coste esperado es , que se simplifica a .

* Big O, Œ©, Œò:

    Estas tres notaciones describen distintos l√≠mites de complejidad. Big O () indica el l√≠mite superior (m√°ximo crecimiento). Omega () indica el l√≠mite inferior (m√≠nimo crecimiento posible). Theta () indica el crecimiento exacto cuando el l√≠mite superior e inferior coinciden. Por ejemplo, para la b√∫squeda lineal, el tiempo de ejecuci√≥n es  en el mejor caso,  en el peor caso, y  en el comportamiento general.


---

## **2. Ejemplos de Complejidad en Java**

---

## **2.1 Complejidad O(1) ‚Äì Constante**

### **Archivo:** `ComplejidadConstante.java`

### **C√≥digo del ejemplo**

```java
public void ejemplo() {
    System.out.println("Ejemplo O(1)");
    int x = 10;
    int y = 5;
    int suma = x + y;
}
```

### **Explicaci√≥n resumida**

*(Aqu√≠ el estudiante explica por qu√© es O(1))*

---
## **2.2 Complejidad O(1) ‚Äì Constante**

### **Archivo:** `ComplejidadConstante.java`

### **C√≥digo del ejemplo**

```java
public void ejemplo() {
    System.out.println("Ejemplo O(1)");
    int x = 10;
    int y = 5;
    int suma = x + y;
}
```

### **Explicaci√≥n resumida**

*(Aqu√≠ el estudiante explica por qu√© es O(1))*

---
## **2.3 Complejidad O(1) ‚Äì Constante**

### **Archivo:** `ComplejidadConstante.java`

### **C√≥digo del ejemplo**

```java
public void ejemplo() {
    System.out.println("Ejemplo O(1)");
    int x = 10;
    int y = 5;
    int suma = x + y;
}
```

### **Explicaci√≥n resumida**

*(Aqu√≠ el estudiante explica por qu√© es O(1))*

---
## **2.4 Complejidad O(1) ‚Äì Constante**

### **Archivo:** `ComplejidadConstante.java`

### **C√≥digo del ejemplo**

```java
public void ejemplo() {
    System.out.println("Ejemplo O(1)");
    int x = 10;
    int y = 5;
    int suma = x + y;
}
```

### **Explicaci√≥n resumida**

*(Aqu√≠ el estudiante explica por qu√© es O(1))*

---
## **2.5 Complejidad O(1) ‚Äì Constante**

### **Archivo:** `ComplejidadConstante.java`

### **C√≥digo del ejemplo**

```java
public void ejemplo() {
    System.out.println("Ejemplo O(1)");
    int x = 10;
    int y = 5;
    int suma = x + y;
}
```

### **Explicaci√≥n resumida**

*(Aqu√≠ el estudiante explica por qu√© es O(1))*

---
**PARA CADA COMPLEJIDAD, REPETIR LA ESTRUCTURA ANTERIOR**


# **Conclusiones**

*(Aqu√≠ el estudiante agrega conclusiones propias del trabajo)*

**POR ESTUDIANTE**: *(Nombre completo del estudiante)*

---